{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BayesianOpt for RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danglive/Optimization-tutorial/blob/master/BayesianOpt_for_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6CLCcg0tC0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "7ecf9c4b-3b5f-4013-9613-ade8266716ad"
      },
      "source": [
        "!pip install scikit-optimize"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
            "\r\u001b[K     |████▍                           | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scikit-optimize) (0.14.0)\n",
            "Installing collected packages: scikit-optimize\n",
            "Successfully installed scikit-optimize-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1AdD5CtIEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "54b9dc39-a9cd-4bf0-95a7-78273e9abfd6"
      },
      "source": [
        "import skopt\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "import atexit\n",
        "from time import time, strftime, localtime\n",
        "from datetime import timedelta\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from  skopt.plots import plot_convergence"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCoa0WAftcok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randomState = 46\n",
        "np.random.seed(randomState)\n",
        "tf.set_random_seed(randomState)\n",
        "\n",
        "\n",
        "input_size=1\n",
        "num_layers=1\n",
        "features = 2\n",
        "column_min_max = [[0, 2000],[0,500000000]]\n",
        "columns = ['Close', 'Volume']\n",
        "\n",
        "\n",
        "num_steps = None\n",
        "lstm_size = None\n",
        "batch_size = None\n",
        "init_learning_rate = None\n",
        "learning_rate_decay = None\n",
        "init_epoch = None\n",
        "max_epoch = None\n",
        "dropout_rate = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-AAkf_BtfPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_num_steps = Integer(low=2, high=14, name='lstm_num_steps')\n",
        "size = Integer(low=8, high=200, name='size')\n",
        "lstm_learning_rate_decay = Real(low=0.7, high=0.99, prior='uniform', name='lstm_learning_rate_decay')\n",
        "lstm_max_epoch = Integer(low=20, high=200, name='lstm_max_epoch')\n",
        "lstm_init_epoch = Integer(low=2, high=50, name='lstm_init_epoch')\n",
        "lstm_batch_size = Integer(low=5, high=100, name='lstm_batch_size')\n",
        "lstm_dropout_rate = Real(low=0.1, high=0.9, prior='uniform', name='lstm_dropout_rate')\n",
        "lstm_init_learning_rate = Real(low=1e-4, high=1e-1, prior='log-uniform', name='lstm_init_learning_rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqShY1ytD2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimensions = [lstm_num_steps, size, lstm_init_epoch, lstm_max_epoch,\n",
        "              lstm_learning_rate_decay, lstm_batch_size, lstm_dropout_rate, lstm_init_learning_rate]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtaQWKdgtknh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_parameters = [2,128,3,30,0.99,64,0.2,0.001]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_rstpKtmuH",
        "colab_type": "text"
      },
      "source": [
        "#------------ to log execution time ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canlx3V0tqMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def secondsToStr(elapsed=None):\n",
        "    if elapsed is None:\n",
        "        return strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n",
        "    else:\n",
        "        return str(timedelta(seconds=elapsed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCW1vX9AtssX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logger(s, elapsed=None):\n",
        "    line = \"=\" * 40\n",
        "    print(line)\n",
        "    print(secondsToStr(), '-', s)\n",
        "    if elapsed:\n",
        "        print(\"Elapsed time:\", elapsed)\n",
        "    print(line)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTwt96LEtvN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def endlog():\n",
        "    end = time()\n",
        "    elapsed = end - start\n",
        "    logger(\"End Program\", secondsToStr(elapsed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNTs1VGHtyci",
        "colab_type": "text"
      },
      "source": [
        "#------------ generate data batches ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJ_MM_oty0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(train_X, train_y, batch_size):\n",
        "    num_batches = int(len(train_X)) // batch_size\n",
        "    if batch_size * num_batches < len(train_X):\n",
        "        num_batches += 1\n",
        "\n",
        "    batch_indices = range(num_batches)\n",
        "    for j in batch_indices:\n",
        "        batch_X = train_X[j * batch_size: (j + 1) * batch_size]\n",
        "        batch_y = train_y[j * batch_size: (j + 1) * batch_size]\n",
        "        yield batch_X, batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSHFgoPYt2BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentation(data):\n",
        "\n",
        "    seq = [price for tup in data[['Close', 'Volume']].values for price in tup]\n",
        "\n",
        "    seq = np.array(seq)\n",
        "\n",
        "    # split into items of features\n",
        "    seq = [np.array(seq[i * features: (i + 1) * features])\n",
        "           for i in range(len(seq) // features)]\n",
        "\n",
        "    # split into groups of num_steps\n",
        "    X = np.array([seq[i: i + num_steps] for i in range(len(seq) - num_steps)])\n",
        "\n",
        "    y = np.array([seq[i + num_steps] for i in range(len(seq) - num_steps)])\n",
        "\n",
        "    # get only sales value\n",
        "    y = [[y[i][0]] for i in range(len(y))]\n",
        "\n",
        "    y = np.asarray(y)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIrPNDht3pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale(data):\n",
        "    for i in range(len(column_min_max)):\n",
        "        data[columns[i]] = (data[columns[i]] - column_min_max[i][0]) / ((column_min_max[i][1]) - (column_min_max[i][0]))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54Z0wQ-t5ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rescle(test_pred):\n",
        "    prediction = [(pred * (column_min_max[0][1] - column_min_max[0][0])) + column_min_max[0][0] for pred in test_pred]\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4AVN7Nt-Iz",
        "colab_type": "text"
      },
      "source": [
        "#------------ fucntion that governs data pre-processing -------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvdjlC5bt_Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process():\n",
        "\n",
        "    stock_data = pd.read_csv('AIG.csv')\n",
        "    stock_data = stock_data.reindex(index=stock_data.index[::-1])\n",
        "\n",
        "    vali_ratio = 0.2\n",
        "    test_ratio = 0.5\n",
        "\n",
        "    train_size = int(len(stock_data) * (1.0 - vali_ratio))\n",
        "    temp_len = len(stock_data)-train_size\n",
        "    validation_len = int(temp_len * (1.0 - test_ratio))\n",
        "    #the final 5% of the data will be for the test set\n",
        "\n",
        "    train_data = stock_data[:train_size]\n",
        "    validation_data = stock_data[(train_size - num_steps): validation_len + train_size]\n",
        "    original_val_data = validation_data.copy()\n",
        "\n",
        "    # -------------- processing train data---------------------------------------\n",
        "    scaled_train_data = scale(train_data)\n",
        "    train_X, train_y = segmentation(scaled_train_data)\n",
        "\n",
        "    # -------------- processing validation data---------------------------------------\n",
        "    scaled_validation_data = scale(validation_data)\n",
        "    val_X, val_y = segmentation(scaled_validation_data)\n",
        "\n",
        "    # ----segmenting original validation data-----------------------------------------------\n",
        "    nonescaled_val_X, nonescaled_val_y = segmentation(original_val_data)\n",
        "\n",
        "\n",
        "    return train_X, train_y, val_X, val_y, nonescaled_val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uboL8BlluEhN",
        "colab_type": "text"
      },
      "source": [
        "#------------ RNN model ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ZHDqmpuBmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setupRNN(inputs,model_dropout_rate):\n",
        "\n",
        "\n",
        "    cell = tf.contrib.rnn.LSTMCell(lstm_size, state_is_tuple=True, activation=tf.nn.tanh,use_peepholes=True)\n",
        "\n",
        "    val1, _ = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
        "\n",
        "    val = tf.transpose(val1, [1, 0, 2])\n",
        "\n",
        "    last = tf.gather(val, int(val.get_shape()[0]) - 1, name=\"last_lstm_output\")\n",
        "\n",
        "    dropout = tf.layers.dropout(last, rate=model_dropout_rate, training=True,seed=46)\n",
        "\n",
        "    weight = tf.Variable(tf.truncated_normal([lstm_size, input_size]))\n",
        "    bias = tf.Variable(tf.constant(0.1, shape=[input_size]))\n",
        "\n",
        "    prediction = tf.matmul(dropout, weight) + bias\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHG7uKZguKO2",
        "colab_type": "text"
      },
      "source": [
        "#------------ function returned to Bayesian Optimization ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3KL6MAvuG_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@use_named_args(dimensions=dimensions)\n",
        "def fitness(lstm_num_steps, size, lstm_init_epoch, lstm_max_epoch,\n",
        "              lstm_learning_rate_decay, lstm_batch_size, lstm_dropout_rate, lstm_init_learning_rate):\n",
        "\n",
        "    global  iteration, num_steps, lstm_size, init_epoch, max_epoch, learning_rate_decay, dropout_rate, init_learning_rate, batch_size\n",
        "\n",
        "    num_steps = np.int32(lstm_num_steps)\n",
        "    lstm_size = np.int32(size)\n",
        "    batch_size = np.int32(lstm_batch_size)\n",
        "    learning_rate_decay = np.float32(lstm_learning_rate_decay)\n",
        "    init_epoch = np.int32(lstm_init_epoch)\n",
        "    max_epoch = np.int32(lstm_max_epoch)\n",
        "    dropout_rate = np.float32(lstm_dropout_rate)\n",
        "    init_learning_rate = np.float32(lstm_init_learning_rate)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(randomState)\n",
        "    sess = tf.Session()\n",
        "\n",
        "    train_X, train_y, val_X, val_y,  nonescaled_val_y = pre_process()\n",
        "\n",
        "    inputs = tf.placeholder(tf.float32, [None, num_steps, features], name=\"inputs\")\n",
        "    targets = tf.placeholder(tf.float32, [None, input_size], name=\"targets\")\n",
        "    model_learning_rate = tf.placeholder(tf.float32, None, name=\"learning_rate\")\n",
        "    model_dropout_rate = tf.placeholder_with_default(0.0, shape=())\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "    prediction = setupRNN(inputs,model_dropout_rate)\n",
        "\n",
        "    model_learning_rate = tf.train.exponential_decay(learning_rate=model_learning_rate, global_step=global_step, decay_rate=learning_rate_decay,\n",
        "                                               decay_steps=init_epoch, staircase=False)\n",
        "\n",
        "    with tf.name_scope('loss'):\n",
        "        model_loss = tf.losses.mean_squared_error(targets, prediction)\n",
        "\n",
        "    with tf.name_scope('adam_optimizer'):\n",
        "        train_step = tf.train.AdamOptimizer(model_learning_rate).minimize(model_loss,global_step=global_step)\n",
        "\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch_step in range(max_epoch):\n",
        "\n",
        "        for batch_X, batch_y in generate_batches(train_X, train_y, batch_size):\n",
        "            train_data_feed = {\n",
        "                inputs: batch_X,\n",
        "                targets: batch_y,\n",
        "                model_learning_rate: init_learning_rate,\n",
        "                model_dropout_rate: dropout_rate\n",
        "            }\n",
        "            sess.run(train_step, train_data_feed)\n",
        "\n",
        "    val_data_feed = {\n",
        "        inputs: val_X,\n",
        "    }\n",
        "    vali_pred = sess.run(prediction, val_data_feed)\n",
        "\n",
        "    vali_pred_vals = rescle(vali_pred)\n",
        "\n",
        "    vali_pred_vals = np.array(vali_pred_vals)\n",
        "\n",
        "    vali_pred_vals = vali_pred_vals.flatten()\n",
        "\n",
        "    vali_pred_vals = vali_pred_vals.tolist()\n",
        "\n",
        "    vali_nonescaled_y = nonescaled_val_y.flatten()\n",
        "\n",
        "    vali_nonescaled_y = vali_nonescaled_y.tolist()\n",
        "\n",
        "    val_error = sqrt(mean_squared_error(vali_nonescaled_y, vali_pred_vals))\n",
        "\n",
        "    return val_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyfLOqguOiG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    start = time()\n",
        "\n",
        "    search_result = gp_minimize(func=fitness,\n",
        "                                dimensions=dimensions,\n",
        "                                acq_func='EI',  # Expected Improvement.\n",
        "                                n_calls=11,\n",
        "                                x0=default_parameters,\n",
        "                                random_state=46)\n",
        "\n",
        "    print(search_result.x)\n",
        "    print(search_result.fun)\n",
        "    plot = plot_convergence(search_result,yscale=\"log\")\n",
        "\n",
        "\n",
        "    atexit.register(endlog)\n",
        "    logger(\"Start Program\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}