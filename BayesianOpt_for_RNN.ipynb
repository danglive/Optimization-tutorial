{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BayesianOpt for RNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danglive/Optimization-tutorial/blob/master/BayesianOpt_for_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6CLCcg0tC0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8e4777ce-5c49-488f-fead-49a70ed56dc3"
      },
      "source": [
        "# Install the library opt\n",
        "!pip install scikit-optimize"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.17.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scikit-optimize) (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1AdD5CtIEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries\n",
        "import skopt\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import sqrt\n",
        "import atexit\n",
        "from time import time, strftime, localtime\n",
        "from datetime import timedelta\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from  skopt.plots import plot_convergence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCoa0WAftcok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the defaut values\n",
        "randomState = 46\n",
        "np.random.seed(randomState)\n",
        "tf.set_random_seed(randomState)\n",
        "\n",
        "\n",
        "input_size=1\n",
        "num_layers=1\n",
        "features = 2\n",
        "column_min_max = [[0, 2000],[0,500000000]]\n",
        "columns = ['Close', 'Volume']\n",
        "\n",
        "\n",
        "num_steps = None\n",
        "lstm_size = None\n",
        "batch_size = None\n",
        "init_learning_rate = None\n",
        "learning_rate_decay = None\n",
        "init_epoch = None\n",
        "max_epoch = None\n",
        "dropout_rate = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-AAkf_BtfPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_num_steps = Integer(low=2, high=14, name='lstm_num_steps')\n",
        "size = Integer(low=8, high=200, name='size')\n",
        "lstm_learning_rate_decay = Real(low=0.7, high=0.99, prior='uniform', name='lstm_learning_rate_decay')\n",
        "lstm_max_epoch = Integer(low=20, high=200, name='lstm_max_epoch')\n",
        "lstm_init_epoch = Integer(low=2, high=50, name='lstm_init_epoch')\n",
        "lstm_batch_size = Integer(low=5, high=100, name='lstm_batch_size')\n",
        "lstm_dropout_rate = Real(low=0.1, high=0.9, prior='uniform', name='lstm_dropout_rate')\n",
        "lstm_init_learning_rate = Real(low=1e-4, high=1e-1, prior='log-uniform', name='lstm_init_learning_rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqShY1ytD2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimensions = [lstm_num_steps, size, lstm_init_epoch, lstm_max_epoch,\n",
        "              lstm_learning_rate_decay, lstm_batch_size, lstm_dropout_rate, lstm_init_learning_rate]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtaQWKdgtknh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_parameters = [2,128,3,30,0.99,64,0.2,0.001]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5_rstpKtmuH",
        "colab_type": "text"
      },
      "source": [
        "#------------ to log execution time ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "canlx3V0tqMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def secondsToStr(elapsed=None):\n",
        "    if elapsed is None:\n",
        "        return strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n",
        "    else:\n",
        "        return str(timedelta(seconds=elapsed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCW1vX9AtssX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logger(s, elapsed=None):\n",
        "    line = \"=\" * 40\n",
        "    print(line)\n",
        "    print(secondsToStr(), '-', s)\n",
        "    if elapsed:\n",
        "        print(\"Elapsed time:\", elapsed)\n",
        "    print(line)\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTwt96LEtvN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def endlog():\n",
        "    end = time()\n",
        "    elapsed = end - start\n",
        "    logger(\"End Program\", secondsToStr(elapsed))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNTs1VGHtyci",
        "colab_type": "text"
      },
      "source": [
        "#------------ generate data batches ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJ_MM_oty0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(train_X, train_y, batch_size):\n",
        "    num_batches = int(len(train_X)) // batch_size\n",
        "    if batch_size * num_batches < len(train_X):\n",
        "        num_batches += 1\n",
        "\n",
        "    batch_indices = range(num_batches)\n",
        "    for j in batch_indices:\n",
        "        batch_X = train_X[j * batch_size: (j + 1) * batch_size]\n",
        "        batch_y = train_y[j * batch_size: (j + 1) * batch_size]\n",
        "        yield batch_X, batch_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSHFgoPYt2BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segmentation(data):\n",
        "\n",
        "    seq = [price for tup in data[['Close', 'Volume']].values for price in tup]\n",
        "\n",
        "    seq = np.array(seq)\n",
        "\n",
        "    # split into items of features\n",
        "    seq = [np.array(seq[i * features: (i + 1) * features])\n",
        "           for i in range(len(seq) // features)]\n",
        "\n",
        "    # split into groups of num_steps\n",
        "    X = np.array([seq[i: i + num_steps] for i in range(len(seq) - num_steps)])\n",
        "\n",
        "    y = np.array([seq[i + num_steps] for i in range(len(seq) - num_steps)])\n",
        "\n",
        "    # get only sales value\n",
        "    y = [[y[i][0]] for i in range(len(y))]\n",
        "\n",
        "    y = np.asarray(y)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntIrPNDht3pW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale(data):\n",
        "    for i in range(len(column_min_max)):\n",
        "        data[columns[i]] = (data[columns[i]] - column_min_max[i][0]) / ((column_min_max[i][1]) - (column_min_max[i][0]))\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I54Z0wQ-t5ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rescle(test_pred):\n",
        "    prediction = [(pred * (column_min_max[0][1] - column_min_max[0][0])) + column_min_max[0][0] for pred in test_pred]\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H4AVN7Nt-Iz",
        "colab_type": "text"
      },
      "source": [
        "#------------ fucntion that governs data pre-processing -------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvdjlC5bt_Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process():\n",
        "    url = 'https://raw.githubusercontent.com/danglive/Optimization-tutorial/master/AIG.csv'\n",
        "    stock_data = pd.read_csv(url)\n",
        "    stock_data = stock_data.reindex(index=stock_data.index[::-1])\n",
        "\n",
        "    vali_ratio = 0.2\n",
        "    test_ratio = 0.5\n",
        "\n",
        "    train_size = int(len(stock_data) * (1.0 - vali_ratio))\n",
        "    temp_len = len(stock_data)-train_size\n",
        "    validation_len = int(temp_len * (1.0 - test_ratio))\n",
        "    #the final 5% of the data will be for the test set\n",
        "\n",
        "    train_data = stock_data[:train_size]\n",
        "    validation_data = stock_data[(train_size - num_steps): validation_len + train_size]\n",
        "    original_val_data = validation_data.copy()\n",
        "\n",
        "    # -------------- processing train data---------------------------------------\n",
        "    scaled_train_data = scale(train_data)\n",
        "    train_X, train_y = segmentation(scaled_train_data)\n",
        "\n",
        "    # -------------- processing validation data---------------------------------------\n",
        "    scaled_validation_data = scale(validation_data)\n",
        "    val_X, val_y = segmentation(scaled_validation_data)\n",
        "\n",
        "    # ----segmenting original validation data-----------------------------------------------\n",
        "    nonescaled_val_X, nonescaled_val_y = segmentation(original_val_data)\n",
        "\n",
        "\n",
        "    return train_X, train_y, val_X, val_y, nonescaled_val_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uboL8BlluEhN",
        "colab_type": "text"
      },
      "source": [
        "#------------ RNN model ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ZHDqmpuBmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setupRNN(inputs,model_dropout_rate):\n",
        "\n",
        "\n",
        "    cell = tf.contrib.rnn.LSTMCell(lstm_size, state_is_tuple=True, activation=tf.nn.tanh,use_peepholes=True)\n",
        "\n",
        "    val1, _ = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
        "\n",
        "    val = tf.transpose(val1, [1, 0, 2])\n",
        "\n",
        "    last = tf.gather(val, int(val.get_shape()[0]) - 1, name=\"last_lstm_output\")\n",
        "\n",
        "    dropout = tf.layers.dropout(last, rate=model_dropout_rate, training=True,seed=46)\n",
        "\n",
        "    weight = tf.Variable(tf.truncated_normal([lstm_size, input_size]))\n",
        "    bias = tf.Variable(tf.constant(0.1, shape=[input_size]))\n",
        "\n",
        "    prediction = tf.matmul(dropout, weight) + bias\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHG7uKZguKO2",
        "colab_type": "text"
      },
      "source": [
        "#------------ function returned to Bayesian Optimization ---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3KL6MAvuG_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@use_named_args(dimensions=dimensions)\n",
        "def fitness(lstm_num_steps, size, lstm_init_epoch, lstm_max_epoch,\n",
        "              lstm_learning_rate_decay, lstm_batch_size, lstm_dropout_rate, lstm_init_learning_rate):\n",
        "\n",
        "    global  iteration, num_steps, lstm_size, init_epoch, max_epoch, learning_rate_decay, dropout_rate, init_learning_rate, batch_size\n",
        "\n",
        "    num_steps = np.int32(lstm_num_steps)\n",
        "    lstm_size = np.int32(size)\n",
        "    batch_size = np.int32(lstm_batch_size)\n",
        "    learning_rate_decay = np.float32(lstm_learning_rate_decay)\n",
        "    init_epoch = np.int32(lstm_init_epoch)\n",
        "    max_epoch = np.int32(lstm_max_epoch)\n",
        "    dropout_rate = np.float32(lstm_dropout_rate)\n",
        "    init_learning_rate = np.float32(lstm_init_learning_rate)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(randomState)\n",
        "    sess = tf.Session()\n",
        "\n",
        "    train_X, train_y, val_X, val_y,  nonescaled_val_y = pre_process()\n",
        "\n",
        "    inputs = tf.placeholder(tf.float32, [None, num_steps, features], name=\"inputs\")\n",
        "    targets = tf.placeholder(tf.float32, [None, input_size], name=\"targets\")\n",
        "    model_learning_rate = tf.placeholder(tf.float32, None, name=\"learning_rate\")\n",
        "    model_dropout_rate = tf.placeholder_with_default(0.0, shape=())\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "    prediction = setupRNN(inputs,model_dropout_rate)\n",
        "\n",
        "    model_learning_rate = tf.train.exponential_decay(learning_rate=model_learning_rate, global_step=global_step, decay_rate=learning_rate_decay,\n",
        "                                               decay_steps=init_epoch, staircase=False)\n",
        "\n",
        "    with tf.name_scope('loss'):\n",
        "        model_loss = tf.losses.mean_squared_error(targets, prediction)\n",
        "\n",
        "    with tf.name_scope('adam_optimizer'):\n",
        "        train_step = tf.train.AdamOptimizer(model_learning_rate).minimize(model_loss,global_step=global_step)\n",
        "\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch_step in range(max_epoch):\n",
        "\n",
        "        for batch_X, batch_y in generate_batches(train_X, train_y, batch_size):\n",
        "            train_data_feed = {\n",
        "                inputs: batch_X,\n",
        "                targets: batch_y,\n",
        "                model_learning_rate: init_learning_rate,\n",
        "                model_dropout_rate: dropout_rate\n",
        "            }\n",
        "            sess.run(train_step, train_data_feed)\n",
        "\n",
        "    val_data_feed = {\n",
        "        inputs: val_X,\n",
        "    }\n",
        "    vali_pred = sess.run(prediction, val_data_feed)\n",
        "\n",
        "    vali_pred_vals = rescle(vali_pred)\n",
        "\n",
        "    vali_pred_vals = np.array(vali_pred_vals)\n",
        "\n",
        "    vali_pred_vals = vali_pred_vals.flatten()\n",
        "\n",
        "    vali_pred_vals = vali_pred_vals.tolist()\n",
        "\n",
        "    vali_nonescaled_y = nonescaled_val_y.flatten()\n",
        "\n",
        "    vali_nonescaled_y = vali_nonescaled_y.tolist()\n",
        "\n",
        "    val_error = sqrt(mean_squared_error(vali_nonescaled_y, vali_pred_vals))\n",
        "\n",
        "    return val_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opyfLOqguOiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b34e6c26-c76c-409b-8d4e-1e4c71282ad4"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    start = time()\n",
        "\n",
        "    search_result = gp_minimize(func=fitness,\n",
        "                                dimensions=dimensions,\n",
        "                                acq_func='EI',  # Expected Improvement.\n",
        "                                n_calls=11,\n",
        "                                x0=default_parameters,\n",
        "                                random_state=46)\n",
        "\n",
        "    print(search_result.x)\n",
        "    print(search_result.fun)\n",
        "    plot = plot_convergence(search_result,yscale=\"log\")\n",
        "\n",
        "\n",
        "    atexit.register(endlog)\n",
        "    logger(\"Start Program\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-7a33ae5d1655>:4: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-26-7a33ae5d1655>:6: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-26-7a33ae5d1655>:12: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:271: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[7, 187, 3, 162, 0.7202483020057686, 68, 0.19990965258462956, 0.0001926747183217011]\n",
            "2.981700600703449\n",
            "========================================\n",
            "2019-11-19 17:57:30 - Start Program\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEYCAYAAACOSYuzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}